http://en.wikipedia.org/wiki/Sync_pulse

Receiving signals

The television system for each country will specify a number of television channels within the UHF or VHF frequency ranges. A channel actually consists of two signals: the picture information is transmitted using amplitude modulation on one frequency, and the sound is transmitted with frequency modulation at a frequency at a fixed offset (typically 4.5 to 6 MHz) from the picture signal.
The channel frequencies chosen represent a compromise between allowing enough bandwidth for video (and hence satisfactory picture resolution), and allowing enough channels to be packed into the available frequency band. In practice a technique called vestigial sideband is used to reduce the channel spacing, which would be at least twice the video bandwidth if pure AM was used.
Signal reception is invariably done via a superheterodyne receiver: the first stage is a tuner which selects a television channel and frequency-shifts it to a fixed intermediate frequency (IF). The signal amplifier (from the microvolt range to fractions of a volt) performs amplification to the IF stages.
[edit]Extracting the sound
At this point the IF signal consists of a video carrier wave at one frequency and the sound carrier at a fixed offset. A demodulator recovers the video signal and sound as an FM signal at the offset frequency (this is known as intercarrier sound).
The FM sound carrier is then demodulated, amplified, and used to drive a loudspeaker. Until the advent of the NICAM and MTS systems, television sound transmissions were invariably monophonic.
[edit]Structure of a video signal
The video carrier is demodulated to give a composite video signal; this contains luminance, chrominance and synchronization signals;[5] this is identical to the video signal format used by analog video devices such as VCRs or CCTV cameras. Note that the RF signal modulation is inverted compared to the conventional AM: the minimum video signal level corresponds to maximum carrier amplitude, and vice versa. The carrier is never shut off altogether; this is to ensure that intercarrier sound demodulation can still occur.

Each line of the displayed image is transmitted using a signal as shown above. The same basic format (with minor differences mainly related to timing and the encoding of color) is used for PAL, NTSC and SECAM television systems. A monochrome signal is identical to a color one, with the exception that the elements shown in color in the diagram (the color burst, and the chrominance signal) are not present.


Portion of a PAL videosignal. From left to right: end of a video scan line, front porch, horizontal sync pulse, back porch with color burst, and beginning of next line
The front porch is a brief (about 1.5 microsecond) period inserted between the end of each transmitted line of picture and the leading edge of the next line sync pulse. Its purpose was to allow voltage levels to stabilise in older televisions, preventing interference between picture lines. The front porch is the first component of the horizontal blanking interval which also contains the horizontal sync pulse and the back porch.[6][7]
The back porch is the portion of each scan line between the end (rising edge) of the horizontal sync pulse and the start of active video. It is used to restore the black level (300 mV.) reference in analog video. In signal processing terms, it compensates for the fall time and settling time following the sync pulse.[6][7]
In color television systems such as PAL and NTSC, this period also includes the colorburst signal. In the SECAM system it contains the reference subcarrier for each consecutive color difference signal in order to set the zero-color reference.
In some professional systems, particularly satellite links between locations, the audio is embedded within the back porch of the video signal, to save the cost of renting a second channel.
[edit]Monochrome video signal extraction
The luminance component of a composite video signal varies between 0 V and approximately 0.7 V above the "black" level. In the NTSC system, there is a blanking signal level used during the front porch and back porch, and a black signal level 75 mV above it; in PAL and SECAM these are identical.
In a monochrome receiver the luminance signal is amplified to drive the control grid in the electron gun of the CRT. This changes the intensity of the electron beam and therefore the brightness of the spot being scanned. Brightness and contrast controls determine the DC shift and amplification, respectively.
[edit]Color video signal extraction


Color bar generator test signal
A color signal conveys picture information for each of the red, green, and blue components of an image (see the article on Color space for more information). However, these are not simply transmitted as three separate signals, because:
Such a signal would not be compatible with monochrome receivers (an important consideration when color broadcasting was first introduced);
it would occupy three times the bandwidth of existing television, requiring a decrease in the number of television channels available; and,
typical problems with signal transmission (such as differing received signal levels between different colors) would produce unpleasant side effects.
Instead, the RGB signals are converted into YUV form, where the Y signal represents the overall brightness, and can be transmitted as the luminance signal. This ensures a monochrome receiver will display a correct picture. The U and V signals are the difference between the Y signal and the B and R signals respectively. The U signal then represents how "blue" the color is, and the V signal how "red" it is. The advantage of this scheme is that the U and V signals are zero when the picture has no color content. Since the human eye is more sensitive to errors in luminance than in color, the U and V signals can be transmitted in a relatively lossy (specifically: bandwidth-limited) way with acceptable results. The G signal is not transmitted in the YUV system, but rather it is recovered electronically at the receiving end.


Color signals mixed with video signal
In the NTSC and PAL color systems, U and V are transmitted by adding a color subcarrier to the composite video signal, and using quadrature amplitude modulation on it. For NTSC, the subcarrier is usually at about 3.58 MHz, but for the PAL system it is at about 4.43 MHz. These frequencies are within the luminance signal band, but their exact frequencies were chosen such that they are midway between two harmonics of the horizontal line repetition rate, thus ensuring that the majority of the power of the luminance signal does not overlap with the power of the chrominance signal.
In the British PAL (D) system, the actual chrominance center frequency is 4.43361875 MHz, a direct multiple of the scan rate frequency. This frequency was chosen to minimize the chrominance beat interference pattern that would be visible in areas of high color saturation in the transmitted picture.
The two signals (U and V) modulate both the amplitude and phase of the color carrier, so to demodulate them it is necessary to have a reference signal against which to compare it. For this reason, a short burst of reference signal known as the color burst is transmitted during the back porch (re-trace period) of each scan line. A reference oscillator in the receiver locks onto this signal (see phase-locked loop) to achieve a phase reference, and uses its amplitude to set an AGC system to achieve an amplitude reference.
The U and V signals are then demodulated by band-pass filtering to retrieve the color subcarrier, mixing it with the in-phase and quadrature signals from the reference oscillator, and low-pass filtering the results.


Test card showing "Hanover Bars" (color banding phase effect) in Pal S (simple) signal mode of transmission.
NTSC uses this process unmodified. Unfortunately, this often results in poor color reproduction due to phase errors in the received signal. The PAL D (delay) system corrects this by reversing the phase of the signal on each successive line, and the averaging the results over pairs of lines. This process is achieved by the use of a 1H (where H = horizontal scan frequency) duration delay line. (A typical circuit used with this device converts the low frequency color signal to ultrasonic sound and back again). Phase shift errors between successive lines are therefore cancelled out and the wanted signal amplitude is increased when the two in-phase (coincident) signals are re-combined.
In the SECAM television system, U and V are transmitted on alternate lines, using simple frequency modulation of two different color subcarriers.
In analog color CRT displays, the brightness control signal (luminance) is fed to the cathode connections of the electron guns, and the color difference signals (chrominance signals) are fed to the control grids connections. This simple matrix mixing technique was replaced in later solid state designs of signal processing.
[edit]Synchronization

Synchronizing pulses added to the video signal at the end of every scan line and video frame ensure that the sweep oscillators in the receiver remain locked in step with the transmitted signal, so that the image can be reconstructed on the receiver screen.[6] [7] [8]
A sync separator circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync. (see section below – Other technical information, for extra detail.)
[edit]Horizontal synchronization
The horizontal synchronization pulse (horizontal sync HSYNC), separates the scan lines. The horizontal sync signal is a single short pulse which indicates the start of every line. The rest of the scan line follows, with the signal ranging from 0.3 V (black) to 1 V (white), until the next horizontal or vertical synchronization pulse.
The format of the horizontal sync pulse varies. In the 525-line NTSC system it is a 4.85 µs-long pulse at 0 V. In the 625-line PAL system the pulse is 4.7 µs synchronization pulse at 0 V . This is lower than the amplitude of any video signal (blacker than black) so it can be detected by the level-sensitive "sync stripper" circuit of the receiver.
[edit]Vertical synchronization
Vertical synchronization (Also vertical sync or VSYNC) separates the video fields. In PAL and NTSC, the vertical sync pulse occurs within the vertical blanking interval. The vertical sync pulses are made by prolonging the length of HSYNC pulses through almost the entire length of the scan line.
The vertical sync signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or mid-way through).
The format of such a signal in 525-line NTSC is:
pre-equalizing pulses (6 to start scanning odd lines, 5 to start scanning even lines)
long-sync pulses (5 pulses)
post-equalizing pulses (5 to start scanning odd lines, 4 to start scanning even lines)
Each pre- or post- equalizing pulse consists in half a scan line of black signal: 2 µs at 0 V, followed by 30 µs at 0.3 V.
Each long sync pulse consists in an equalizing pulse with timings inverted: 30 µs at 0 V, followed by 2 µs at 0.3 V.
In video production and computer graphics, changes to the image are often kept in step with the vertical synchronization pulse to avoid visible discontinuity of the image. Since the frame buffer of a computer graphics display imitates the dynamics of a cathode-ray display, if it is updated with a new image while the image is being transmitted to the display, the display shows a mishmash of both frames, producing a page tearing artifact partway down the image.
Vertical synchronization eliminates this by timing frame buffer fills to coincide with the vertical blanking interval, thus ensuring that only whole frames are seen on-screen. Software such as video games and computer aided design (CAD) packages often allow vertical synchronization as an option, because it delays the image update until the vertical blanking interval. This produces a small penalty in latency, because the program has to wait until the video controller has finished transmitting the image to the display before continuing. Triple buffering reduces this latency significantly.
Two timing intervals are defined – the front porch between the end of displayed video and the start of the sync pulse, and the back porch after the sync pulse and before displayed video. These and the sync pulse itself are called the horizontal blanking (or retrace) interval and represent the time that the electron beam in the CRT is returning to the start of the next display line.
[edit]Horizontal hold and vertical hold
The lack of precision timing components available in early television receivers meant that the timebase circuits occasionally needed manual adjustment. The adjustment took the form of horizontal hold and vertical hold controls, usually on the rear[citation needed] of the television set. Loss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.